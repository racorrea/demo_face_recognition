{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de rostros y reconocimiento facial\n",
    "\n",
    "## Librerías\n",
    "\n",
    "Este proyecto está desarrollado bajo la **versión 3.8 de python** por medio del entorno de **Anaconda para Windows**, además se hará uso de la última versión de **openCV** en conjunto con el algoritmo **LPBH** para la creación de un modelo para el reconocimiento facial.\n",
    "\n",
    "> **Anaconda:** https://docs.anaconda.com/anaconda/install/windows/\n",
    "\n",
    "> **OpenCV:** conda install -c conda-forge opencv\n",
    "\n",
    "> **Modelo Detección de rostros:** Descargar archivo \"haarcascade_frontalface_alt.xml\" desde https://github.com/opencv/opencv/tree/master/data/haarcascades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image # For face recognition we will the the LBPH Face Recognizer \n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Captura de imágenes para entrenamiento\n",
    " \n",
    "En el siguiente código la variable **id** representa el identificador por cada persona con la que se desea entrenar el modelo, este debe incrementar por cada nuevo rostro. \n",
    "\n",
    "Los pasos siguientes se enciende la cámara del dispositivo para obtener los rostros con ayuda del modelo para la detección de los mismo, que se encuentra en la variable: **face_cascade**, para mejorar la precisión la imagen se convierte a escala de grises y se configuran los parámetros para la detección de rostros en **1.1**, este factor controla el reescalado de la imagen que es de gran importancia para detectar rostros según su tamaño en la imagen.\n",
    "\n",
    "En la carpeta **img_train** se almacenan los rostros obtenidos que en este ejemplo se toman un total de 20, el nombre de cada archivo contiene el formato **User.1.1** el primer valor es el de la variable **id** y el siguiente un incremental por las 20 imágenes que se van a generar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImages(id, source):\n",
    "\n",
    "    cap = cv2.VideoCapture(source)\n",
    "\n",
    "    cont=0; #Contador por cada rostro detectado y almacenado\n",
    "\n",
    "    facesLimit=30; #Cantidad de rostros a obtener\n",
    "\n",
    "    while 1:\n",
    "\n",
    "        ret, img = cap.read() #Inicia cámara y obtiene fotogramas\n",
    "        \n",
    "        if (ret):\n",
    "\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #Convierte la imagen a escala de grises\n",
    "\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.2, 5)\n",
    "\n",
    "            for (x,y,w,h) in faces:\n",
    "\n",
    "                cont=cont+1;\n",
    "\n",
    "                cv2.imwrite(\"img_train/User.\"+str(id)+ \".\" +str(cont)+ \".jpg\", gray[y:y+h, x:x+w])\n",
    "\n",
    "                cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "                cv2.waitKey(100)\n",
    "\n",
    "            cv2.imshow('img',img)\n",
    "\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "            if cont > facesLimit:\n",
    "\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener imágenes desde la cámara se debe especificar el valor **id** (primer parámetro) y el valor **source** (segundo parámetro), para el cual especificar **0** corresponde a usar la cámara mientras que si se especifica una ruta, se tomara las capturas desde un video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getImages(1, 0) #Obtener imagenes desde camara\n",
    "getImages(1, 'video_train/train_1.mp4') #Obtener imagenes desde video id:1\n",
    "getImages(2, 'video_train/train_2.mp4') #Obtener imagenes desde video id:2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Creación de modelo\n",
    " \n",
    "El siguiente bloque contiene el entrenamiento del modelo para el reconocimiento facial, se toman las imágenes generadas en la carpeta **img_train** por cada persona y obtiene las características encontradas relacionándolas al **id** de cada imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "path=\"img_train\"\n",
    "\n",
    "def getImagesWithID(path):\n",
    "\n",
    "    imagePaths = [os.path.join(path, f) for f in os.listdir(path)]   # Obtiene imagenes del directorio\n",
    "\n",
    "    faces = []\n",
    "\n",
    "    IDs = []\n",
    "\n",
    "    for imagePath in imagePaths: # Loop por cada imagen encontrada\n",
    "\n",
    "        facesImg = Image.open(imagePath).convert('L') # Convierte la imagen a escala de grises\n",
    "\n",
    "        faceNP = np.array(facesImg, 'uint8') # Genera matriz con pixeles de la imagen \n",
    "\n",
    "        ID= int(os.path.split(imagePath)[-1].split(\".\")[1]) #Obtiene id asignnado a la imagen\n",
    "\n",
    "        faces.append(faceNP) # Asocia características de los rostros\n",
    "\n",
    "        IDs.append(ID) # Almacena id por conjunto de imagenes analizadas\n",
    "\n",
    "        cv2.imshow(\"Rostros para entrenamiento\",faceNP) # Muestra en pantalla el proceso\n",
    "\n",
    "        cv2.waitKey(10)\n",
    "\n",
    "    return np.array(IDs), faces # Devuelve matrices por cada imagen asociada a una misma persona y el respectivo id\n",
    "\n",
    "Ids,faces  = getImagesWithID(path) # Llama a función para obtener matrices de las imagenes\n",
    "\n",
    "recognizer.train(faces,Ids) # Entrena el modelo\n",
    "\n",
    "recognizer.save(\"face_model/trainingdata.yml\") # Se almacena el modelo\n",
    "\n",
    "cv2.destroyAllWindows() # Se cierran las ventanas abiertas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba modelo en tiempo real con la cámara del dispositivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "rec = cv2.face.LBPHFaceRecognizer_create();\n",
    "rec.read(\"face_model/trainingdata.yml\")\n",
    "id=0\n",
    "\n",
    "fontface = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontscale = 1\n",
    "fontcolor = (255, 255, 255)\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.5, 3)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        id,conf=rec.predict(gray[y:y+h,x:x+w])\n",
    "        if(id==1):\n",
    "            id=\"Keanu Reeves\"\n",
    "        if id==2:\n",
    "            id=\"Laurence Fishburne\"\n",
    "        cv2.putText(img, str(id), (x,y+h), fontface, fontscale, fontcolor) \n",
    "        \n",
    "    cv2.imshow('img',img)\n",
    "    \n",
    "    #Salir con 'ESC':\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba modelo con una imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mostrando resultado. Pulsa cualquier tecla para salir.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "rec = cv2.face.LBPHFaceRecognizer_create();\n",
    "rec.read(\"face_model/trainingdata.yml\")\n",
    "id=0\n",
    "\n",
    "fontface = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontscale = 1\n",
    "fontcolor = (255, 255, 255)\n",
    "\n",
    "img = cv2.imread('img_test/1.jpg')\n",
    "\n",
    "scale_percent = 100 # percent of original size\n",
    "\n",
    "width = int(img.shape[1] * scale_percent / 100)\n",
    "height = int(img.shape[0] * scale_percent / 100)\n",
    "\n",
    "dim = (width, height)\n",
    "# resize image\n",
    "img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.5, 5)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    id,conf=rec.predict(gray[y:y+h,x:x+w])\n",
    "    if id==1:\n",
    "        id=\"Keanu Reeves\"\n",
    "    if id==2:\n",
    "        id=\"Laurence Fishburne\"\n",
    "    cv2.putText(img, str(id), (x,y+h), fontface, fontscale, fontcolor) \n",
    "    \n",
    "cv2.imshow('img',img)\n",
    "print(\"\\nMostrando resultado. Pulsa cualquier tecla para salir.\\n\")\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba modelo con un video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture('video_test/1.mp4')\n",
    "rec = cv2.face.LBPHFaceRecognizer_create();\n",
    "rec.read(\"face_model/trainingdata.yml\")\n",
    "id=0\n",
    "\n",
    "fontface = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontscale = 1\n",
    "fontcolor = (255, 255, 255)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    if ret == True:\n",
    "        scale_percent = 50 # percent of original size\n",
    "\n",
    "        width = int(img.shape[1] * scale_percent / 100)\n",
    "        height = int(img.shape[0] * scale_percent / 100)\n",
    "\n",
    "        dim = (width, height)\n",
    "        # resize image\n",
    "        img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.5, 5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            id,conf=rec.predict(gray[y:y+h,x:x+w])\n",
    "            if id==1:\n",
    "                id=\"Keanu Reeves \"\n",
    "            if id==2:\n",
    "                id=\"Laurence Fishburne \"\n",
    "            cv2.putText(img, str(id), (x,y+h), fontface, fontscale, fontcolor) \n",
    "\n",
    "        cv2.imshow('img',img)\n",
    "\n",
    "        #Salir con 'ESC':\n",
    "        k = cv2.waitKey(5) & 0xFF\n",
    "        if k == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    ">El algoritmo para reconocimiento facial forma parte de las librerías de OpenCV, este tiene sus limitantes ya que no permite obtener el nivel de precisión cuando se evalúa un rostro, por lo cual existen imprecisiones al encontrar rostros similares o desconocidos.\n",
    "\n",
    ">Obtener imagen variadas y en distintas situaciones puede mejorar la precisión de cualquier modelo.\n",
    "\n",
    ">El factor de reescalado en el modelo para detección de rostros puede afectar el resultado, un nivel mas bajo permite encontrar mas rostros, sin embargo, esto puede ser contra producente ya que puede llegar a tomar objetos que no representan un rostro, pero si características que el modelo considera similares a las de un rostro.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
